{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45165ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee5016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20147d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedre\\AppData\\Local\\Temp\\ipykernel_18108\\1856430943.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  MRCONSO = pd.read_csv(\"C:/Users/vedre/Downloads/2023AA/META/MRCONSO.RRF\",sep=\"|\",index_col=False,names=[\"CUI\",\"LAT\",\"TS\",\"LUI\",\"STT\",\"SUI\",\"ISPREF\",\"AUI\",\"SAUI\",\"SCUI\",\"SDUI\",\"SAB\",\"TTY\",\"CODE\",\"STR\",\"SRL\",\"SUPPRESS\",\"CVF\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI</th>\n",
       "      <th>LAT</th>\n",
       "      <th>TS</th>\n",
       "      <th>LUI</th>\n",
       "      <th>STT</th>\n",
       "      <th>SUI</th>\n",
       "      <th>ISPREF</th>\n",
       "      <th>AUI</th>\n",
       "      <th>SAUI</th>\n",
       "      <th>SCUI</th>\n",
       "      <th>SDUI</th>\n",
       "      <th>SAB</th>\n",
       "      <th>TTY</th>\n",
       "      <th>CODE</th>\n",
       "      <th>STR</th>\n",
       "      <th>SRL</th>\n",
       "      <th>SUPPRESS</th>\n",
       "      <th>CVF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000005</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L0000005</td>\n",
       "      <td>PF</td>\n",
       "      <td>S0007492</td>\n",
       "      <td>Y</td>\n",
       "      <td>A26634265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0019694</td>\n",
       "      <td>D012711</td>\n",
       "      <td>MSH</td>\n",
       "      <td>PEP</td>\n",
       "      <td>D012711</td>\n",
       "      <td>(131)I-Macroaggregated Albumin</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0000005</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L0270109</td>\n",
       "      <td>PF</td>\n",
       "      <td>S0007491</td>\n",
       "      <td>Y</td>\n",
       "      <td>A26634266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0019694</td>\n",
       "      <td>D012711</td>\n",
       "      <td>MSH</td>\n",
       "      <td>ET</td>\n",
       "      <td>D012711</td>\n",
       "      <td>(131)I-MAA</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0000005</td>\n",
       "      <td>FRE</td>\n",
       "      <td>P</td>\n",
       "      <td>L6220710</td>\n",
       "      <td>PF</td>\n",
       "      <td>S7133957</td>\n",
       "      <td>Y</td>\n",
       "      <td>A13433185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0019694</td>\n",
       "      <td>D012711</td>\n",
       "      <td>MSHFRE</td>\n",
       "      <td>PEP</td>\n",
       "      <td>D012711</td>\n",
       "      <td>Macroagrégats d'albumine marquée à l'iode 131</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0000005</td>\n",
       "      <td>FRE</td>\n",
       "      <td>S</td>\n",
       "      <td>L6215648</td>\n",
       "      <td>PF</td>\n",
       "      <td>S7133916</td>\n",
       "      <td>Y</td>\n",
       "      <td>A27488794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0019694</td>\n",
       "      <td>D012711</td>\n",
       "      <td>MSHFRE</td>\n",
       "      <td>ET</td>\n",
       "      <td>D012711</td>\n",
       "      <td>MAA-I 131</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0000005</td>\n",
       "      <td>FRE</td>\n",
       "      <td>S</td>\n",
       "      <td>L6215656</td>\n",
       "      <td>PF</td>\n",
       "      <td>S7133956</td>\n",
       "      <td>Y</td>\n",
       "      <td>A27614225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0019694</td>\n",
       "      <td>D012711</td>\n",
       "      <td>MSHFRE</td>\n",
       "      <td>ET</td>\n",
       "      <td>D012711</td>\n",
       "      <td>Macroagrégats d'albumine humaine marquée à l'i...</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501903</th>\n",
       "      <td>C5779498</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L18667936</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371122</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35434310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VAB</td>\n",
       "      <td>V-LNC-TR-TR_274</td>\n",
       "      <td>LNC-TR-TR_274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501904</th>\n",
       "      <td>C5779499</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L18669902</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371143</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35435041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VPT</td>\n",
       "      <td>V-LNC-UK-UA_274</td>\n",
       "      <td>LOINC, Ukrainian, Ukraine Edition, 274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501905</th>\n",
       "      <td>C5779499</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L18668977</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371123</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35434902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VAB</td>\n",
       "      <td>V-LNC-UK-UA_274</td>\n",
       "      <td>LNC-UK-UA_274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501906</th>\n",
       "      <td>C5779500</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L18664988</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371125</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35435932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VPT</td>\n",
       "      <td>V-LNC-ZH-CN_274</td>\n",
       "      <td>LOINC, Chinese, China Edition, 274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501907</th>\n",
       "      <td>C5779500</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L18665971</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371124</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35438684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VAB</td>\n",
       "      <td>V-LNC-ZH-CN_274</td>\n",
       "      <td>LNC-ZH-CN_274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13501908 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CUI  LAT TS        LUI STT        SUI ISPREF        AUI  SAUI  \\\n",
       "0         C0000005  ENG  P   L0000005  PF   S0007492      Y  A26634265   NaN   \n",
       "1         C0000005  ENG  S   L0270109  PF   S0007491      Y  A26634266   NaN   \n",
       "2         C0000005  FRE  P   L6220710  PF   S7133957      Y  A13433185   NaN   \n",
       "3         C0000005  FRE  S   L6215648  PF   S7133916      Y  A27488794   NaN   \n",
       "4         C0000005  FRE  S   L6215656  PF   S7133956      Y  A27614225   NaN   \n",
       "...            ...  ... ..        ...  ..        ...    ...        ...   ...   \n",
       "13501903  C5779498  ENG  S  L18667936  PF  S22371122      Y  A35434310   NaN   \n",
       "13501904  C5779499  ENG  P  L18669902  PF  S22371143      Y  A35435041   NaN   \n",
       "13501905  C5779499  ENG  S  L18668977  PF  S22371123      Y  A35434902   NaN   \n",
       "13501906  C5779500  ENG  P  L18664988  PF  S22371125      Y  A35435932   NaN   \n",
       "13501907  C5779500  ENG  S  L18665971  PF  S22371124      Y  A35438684   NaN   \n",
       "\n",
       "              SCUI     SDUI     SAB  TTY             CODE  \\\n",
       "0         M0019694  D012711     MSH  PEP          D012711   \n",
       "1         M0019694  D012711     MSH   ET          D012711   \n",
       "2         M0019694  D012711  MSHFRE  PEP          D012711   \n",
       "3         M0019694  D012711  MSHFRE   ET          D012711   \n",
       "4         M0019694  D012711  MSHFRE   ET          D012711   \n",
       "...            ...      ...     ...  ...              ...   \n",
       "13501903       NaN      NaN     SRC  VAB  V-LNC-TR-TR_274   \n",
       "13501904       NaN      NaN     SRC  VPT  V-LNC-UK-UA_274   \n",
       "13501905       NaN      NaN     SRC  VAB  V-LNC-UK-UA_274   \n",
       "13501906       NaN      NaN     SRC  VPT  V-LNC-ZH-CN_274   \n",
       "13501907       NaN      NaN     SRC  VAB  V-LNC-ZH-CN_274   \n",
       "\n",
       "                                                        STR  SRL SUPPRESS  \\\n",
       "0                            (131)I-Macroaggregated Albumin    0        N   \n",
       "1                                                (131)I-MAA    0        N   \n",
       "2             Macroagrégats d'albumine marquée à l'iode 131    3        N   \n",
       "3                                                 MAA-I 131    3        N   \n",
       "4         Macroagrégats d'albumine humaine marquée à l'i...    3        N   \n",
       "...                                                     ...  ...      ...   \n",
       "13501903                                      LNC-TR-TR_274    0        N   \n",
       "13501904             LOINC, Ukrainian, Ukraine Edition, 274    0        N   \n",
       "13501905                                      LNC-UK-UA_274    0        N   \n",
       "13501906                 LOINC, Chinese, China Edition, 274    0        N   \n",
       "13501907                                      LNC-ZH-CN_274    0        N   \n",
       "\n",
       "            CVF  \n",
       "0         256.0  \n",
       "1         256.0  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "13501903    NaN  \n",
       "13501904    NaN  \n",
       "13501905    NaN  \n",
       "13501906    NaN  \n",
       "13501907    NaN  \n",
       "\n",
       "[13501908 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRCONSO = pd.read_csv(\"C:/Users/vedre/Downloads/2023AA/META/MRCONSO.RRF\",sep=\"|\",index_col=False,names=[\"CUI\",\"LAT\",\"TS\",\"LUI\",\"STT\",\"SUI\",\"ISPREF\",\"AUI\",\"SAUI\",\"SCUI\",\"SDUI\",\"SAB\",\"TTY\",\"CODE\",\"STR\",\"SRL\",\"SUPPRESS\",\"CVF\"])\n",
    "MRCONSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9956472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI</th>\n",
       "      <th>LAT</th>\n",
       "      <th>TS</th>\n",
       "      <th>LUI</th>\n",
       "      <th>STT</th>\n",
       "      <th>SUI</th>\n",
       "      <th>ISPREF</th>\n",
       "      <th>AUI</th>\n",
       "      <th>SAUI</th>\n",
       "      <th>SCUI</th>\n",
       "      <th>SDUI</th>\n",
       "      <th>SAB</th>\n",
       "      <th>TTY</th>\n",
       "      <th>CODE</th>\n",
       "      <th>STR</th>\n",
       "      <th>SRL</th>\n",
       "      <th>SUPPRESS</th>\n",
       "      <th>CVF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000005</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L0000005</td>\n",
       "      <td>PF</td>\n",
       "      <td>S0007492</td>\n",
       "      <td>Y</td>\n",
       "      <td>A26634265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0019694</td>\n",
       "      <td>D012711</td>\n",
       "      <td>MSH</td>\n",
       "      <td>PEP</td>\n",
       "      <td>D012711</td>\n",
       "      <td>(131)I-Macroaggregated Albumin</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0000005</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L0270109</td>\n",
       "      <td>PF</td>\n",
       "      <td>S0007491</td>\n",
       "      <td>Y</td>\n",
       "      <td>A26634266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0019694</td>\n",
       "      <td>D012711</td>\n",
       "      <td>MSH</td>\n",
       "      <td>ET</td>\n",
       "      <td>D012711</td>\n",
       "      <td>(131)I-MAA</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L0000039</td>\n",
       "      <td>PF</td>\n",
       "      <td>S17175117</td>\n",
       "      <td>N</td>\n",
       "      <td>A28315139</td>\n",
       "      <td>9194921.0</td>\n",
       "      <td>1926948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RXNORM</td>\n",
       "      <td>IN</td>\n",
       "      <td>1926948</td>\n",
       "      <td>1,2-dipalmitoylphosphatidylcholine</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L0000039</td>\n",
       "      <td>PF</td>\n",
       "      <td>S17175117</td>\n",
       "      <td>Y</td>\n",
       "      <td>A28572604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTH</td>\n",
       "      <td>PN</td>\n",
       "      <td>NOCODE</td>\n",
       "      <td>1,2-dipalmitoylphosphatidylcholine</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L0000039</td>\n",
       "      <td>VC</td>\n",
       "      <td>S0007564</td>\n",
       "      <td>Y</td>\n",
       "      <td>A0016515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0023172</td>\n",
       "      <td>D015060</td>\n",
       "      <td>MSH</td>\n",
       "      <td>MH</td>\n",
       "      <td>D015060</td>\n",
       "      <td>1,2-Dipalmitoylphosphatidylcholine</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501903</th>\n",
       "      <td>C5779498</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L18667936</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371122</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35434310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VAB</td>\n",
       "      <td>V-LNC-TR-TR_274</td>\n",
       "      <td>LNC-TR-TR_274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501904</th>\n",
       "      <td>C5779499</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L18669902</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371143</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35435041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VPT</td>\n",
       "      <td>V-LNC-UK-UA_274</td>\n",
       "      <td>LOINC, Ukrainian, Ukraine Edition, 274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501905</th>\n",
       "      <td>C5779499</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L18668977</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371123</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35434902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VAB</td>\n",
       "      <td>V-LNC-UK-UA_274</td>\n",
       "      <td>LNC-UK-UA_274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501906</th>\n",
       "      <td>C5779500</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L18664988</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371125</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35435932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VPT</td>\n",
       "      <td>V-LNC-ZH-CN_274</td>\n",
       "      <td>LOINC, Chinese, China Edition, 274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501907</th>\n",
       "      <td>C5779500</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L18665971</td>\n",
       "      <td>PF</td>\n",
       "      <td>S22371124</td>\n",
       "      <td>Y</td>\n",
       "      <td>A35438684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SRC</td>\n",
       "      <td>VAB</td>\n",
       "      <td>V-LNC-ZH-CN_274</td>\n",
       "      <td>LNC-ZH-CN_274</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8510801 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CUI  LAT TS        LUI STT        SUI ISPREF        AUI  \\\n",
       "0         C0000005  ENG  P   L0000005  PF   S0007492      Y  A26634265   \n",
       "1         C0000005  ENG  S   L0270109  PF   S0007491      Y  A26634266   \n",
       "10        C0000039  ENG  P   L0000039  PF  S17175117      N  A28315139   \n",
       "11        C0000039  ENG  P   L0000039  PF  S17175117      Y  A28572604   \n",
       "12        C0000039  ENG  P   L0000039  VC   S0007564      Y   A0016515   \n",
       "...            ...  ... ..        ...  ..        ...    ...        ...   \n",
       "13501903  C5779498  ENG  S  L18667936  PF  S22371122      Y  A35434310   \n",
       "13501904  C5779499  ENG  P  L18669902  PF  S22371143      Y  A35435041   \n",
       "13501905  C5779499  ENG  S  L18668977  PF  S22371123      Y  A35434902   \n",
       "13501906  C5779500  ENG  P  L18664988  PF  S22371125      Y  A35435932   \n",
       "13501907  C5779500  ENG  S  L18665971  PF  S22371124      Y  A35438684   \n",
       "\n",
       "               SAUI      SCUI     SDUI     SAB  TTY             CODE  \\\n",
       "0               NaN  M0019694  D012711     MSH  PEP          D012711   \n",
       "1               NaN  M0019694  D012711     MSH   ET          D012711   \n",
       "10        9194921.0   1926948      NaN  RXNORM   IN          1926948   \n",
       "11              NaN       NaN      NaN     MTH   PN           NOCODE   \n",
       "12              NaN  M0023172  D015060     MSH   MH          D015060   \n",
       "...             ...       ...      ...     ...  ...              ...   \n",
       "13501903        NaN       NaN      NaN     SRC  VAB  V-LNC-TR-TR_274   \n",
       "13501904        NaN       NaN      NaN     SRC  VPT  V-LNC-UK-UA_274   \n",
       "13501905        NaN       NaN      NaN     SRC  VAB  V-LNC-UK-UA_274   \n",
       "13501906        NaN       NaN      NaN     SRC  VPT  V-LNC-ZH-CN_274   \n",
       "13501907        NaN       NaN      NaN     SRC  VAB  V-LNC-ZH-CN_274   \n",
       "\n",
       "                                             STR  SRL SUPPRESS    CVF  \n",
       "0                 (131)I-Macroaggregated Albumin    0        N  256.0  \n",
       "1                                     (131)I-MAA    0        N  256.0  \n",
       "10            1,2-dipalmitoylphosphatidylcholine    0        N  256.0  \n",
       "11            1,2-dipalmitoylphosphatidylcholine    0        N  256.0  \n",
       "12            1,2-Dipalmitoylphosphatidylcholine    0        N    NaN  \n",
       "...                                          ...  ...      ...    ...  \n",
       "13501903                           LNC-TR-TR_274    0        N    NaN  \n",
       "13501904  LOINC, Ukrainian, Ukraine Edition, 274    0        N    NaN  \n",
       "13501905                           LNC-UK-UA_274    0        N    NaN  \n",
       "13501906      LOINC, Chinese, China Edition, 274    0        N    NaN  \n",
       "13501907                           LNC-ZH-CN_274    0        N    NaN  \n",
       "\n",
       "[8510801 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRCONSO_ENG = MRCONSO[MRCONSO[\"LAT\"] == 'ENG']\n",
    "MRCONSO_ENG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by \"CUI\" and count occurrences\n",
    "cui_counts = MRCONSO_ENG.groupby(\"CUI\").size()\n",
    "\n",
    "cui_counts = cui_counts[cui_counts >= 1]\n",
    "\n",
    "# Use the filtered \"CUI\" values to create a Boolean mask\n",
    "cui_mask = MRCONSO_ENG[\"CUI\"].isin(cui_counts.index)\n",
    "\n",
    "# Filter the DataFrame using the Boolean mask\n",
    "MRCONSO_filtered = MRCONSO_ENG[cui_mask]\n",
    "MRCONSO_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = [\n",
    "    \"AIR\", \"ALT\", \"AOD\", \"AOT\", \"ATC\", \"BI\", \"CCC\", \"CCPSS\", \"CCS\", \"CCSR_ICD10CM\", \n",
    "    \"CCSR_ICD10PCS\", \"CDCREC\", \"CDT\", \"CHV\", \"COSTAR\", \"CPM\", \"CPT\", \"CSP\", \"CST\", \n",
    "    \"CVX\", \"DDB\", \"DRUGBANK\", \"DSM-5\", \"DXP\", \"FMA\", \"GO\", \"GS\", \"HCDT\", \"HCPCS\", \n",
    "    \"HCPT\", \"HGNC\", \"HL7V2.5\", \"HL7V3.0\", \"HPO\", \"ICD10\", \"ICD10AE\", \"ICD10AM\", \n",
    "    \"ICD10AMAE\", \"ICD10CM\", \"ICD10PCS\", \"ICD9CM\", \"ICF\", \"ICF-CY\", \"ICNP\", \"ICPC\", \n",
    "    \"ICPC2EENG\", \"ICPC2ICD10ENG\", \"ICPC2P\", \"JABL\", \"LCH\", \"LCH_NW\", \"LNC\", \"MCM\", \n",
    "    \"MDR\", \"MED-RT\", \"MEDCIN\", \"MEDLINEPLUS\", \"MMSL\", \"MMX\", \"MSH\", \"MTH\", \n",
    "    \"MTHCMSFRF\", \"MTHICD9\", \"MTHICPC2EAE\", \"MTHICPC2ICD10AE\", \"MTHMST\", \"MTHSPL\", \n",
    "    \"MVX\", \"NANDA-I\", \"NCBI\", \"NCI\", \"NDDF\", \"NEU\", \"NIC\", \"NOC\", \"NUCCHCPT\", \n",
    "    \"OMIM\", \"OMS\", \"ORPHANET\", \"PCDS\", \"PDQ\", \"PNDS\", \"PPAC\", \"PSY\", \"QMR\", \"RAM\", \n",
    "    \"RCD\", \"RCDAE\", \"RCDSA\", \"RCDSY\", \"RXNORM\", \"SNM\", \"SNMI\", \"SNOMEDCT_US\", \n",
    "    \"SNOMEDCT_VET\", \"SOP\", \"SPN\", \"SRC\", \"ULT\", \"UMD\", \"USP\", \"USPMG\", \"UWDA\", \n",
    "    \"VANDF\", \"WHO\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_list = []\n",
    "for v in tqdm(vocabs):\n",
    "    cuis = MRCONSO_filtered.loc[MRCONSO_filtered['SAB'] == v, 'CUI'].unique().tolist()\n",
    "    cui_list.extend(cuis)\n",
    "    \n",
    "cui_list = list(set(cui_list))\n",
    "len(cui_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc537a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names with 'CUI' in the 0th place\n",
    "column_names = ['CUI', 'TUI', 'STN', 'STY', 'ATUI', 'CVF']\n",
    "\n",
    "# Read the file into a DataFrame without setting 'CUI' as the index\n",
    "MRSTY = pd.read_csv('C:/Users/vedre/Downloads/2023AA/META/MRSTY.RRF', sep='|', header=None, names=column_names, index_col=False)\n",
    "MRSTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ee7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRSTY_FILTERED = MRSTY[MRSTY['CUI'].isin(cui_list)]\n",
    "MRSTY_FILTERED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique TUI values\n",
    "unique_tui_values = MRSTY_FILTERED['TUI'].unique()\n",
    "\n",
    "# Initialize an empty dictionary to store STY values for each TUI\n",
    "tui_sty_dict = {}\n",
    "\n",
    "# Iterate through unique TUI values and collect corresponding STY values\n",
    "for tui in unique_tui_values:\n",
    "    # Filter the DataFrame for rows with the current TUI\n",
    "    tui_df = MRSTY_FILTERED[MRSTY_FILTERED['TUI'] == tui]\n",
    "    \n",
    "    # Extract and join the unique STY values with '*'\n",
    "    sty_values = '*'.join(tui_df['STY'].unique())\n",
    "    \n",
    "    # Store the STY values for the current TUI in the dictionary\n",
    "    tui_sty_dict[tui] = sty_values\n",
    "\n",
    "# Print the TUI and corresponding STY values\n",
    "for tui, sty in tui_sty_dict.items():\n",
    "    print(f'{tui} - {sty}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67375ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of TUI values you want to filter by\n",
    "desired_tui_values = [\n",
    "    'T017', 'T021', 'T022', 'T023', 'T024',\n",
    "    'T025', 'T026', 'T029', 'T030', 'T031',\n",
    "    'T125', 'T192'\n",
    "]\n",
    "\n",
    "# Create a boolean mask that checks if 'TUI' is in the list of desired values\n",
    "mask = MRSTY_FILTERED['TUI'].isin(desired_tui_values)\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "MRSTY_TUI = MRSTY_FILTERED[mask]\n",
    "MRSTY_TUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658180e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique CUI values from the filtered DataFrame\n",
    "unique_cui_values = MRSTY_TUI['CUI'].unique()\n",
    "\n",
    "# Convert the unique CUI values to a Python list\n",
    "cui_tui_list = list(unique_cui_values)\n",
    "len(cui_tui_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf600fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRREL = pd.read_csv(\"C:/Users/vedre/Downloads/2023AA/META/MRREL.RRF\",sep=\"|\",index_col=False,names=[\"CUI1\",\"AUI1\",\"STYPE1\",\"REL\",\"CUI2\",\"AUI2\",\"STYPE2\",\"RELA\",\"RUI\",\"SRUI\",\"SAB\",\"SL\",\"RG\",\"DIR\",\"SUPPRESS\",\"CVF\"])\n",
    "MRREL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecbea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRREL_filtered = MRREL[MRREL['CUI1'].isin(cui_tui_list) & MRREL['CUI2'].isin(cui_tui_list)]\n",
    "MRREL_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRREL_VOC = pd.DataFrame()\n",
    "for v in tqdm(vocabs):\n",
    "    MRREL_VOC = pd.concat([MRREL_VOC, MRREL_filtered[MRREL_filtered['SAB'] == v]], ignore_index=True)    \n",
    "MRREL_VOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRREL_CHD = MRREL_VOC[MRREL_VOC[\"REL\"] == 'CHD']\n",
    "MRREL_CHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRREL_U = MRREL_CHD[MRREL_CHD[\"CUI1\"] != MRREL_CHD[\"CUI2\"]]\n",
    "MRREL_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for _, row in tqdm(MRREL_U.iterrows(), total=len(MRREL_U)):\n",
    "    G.add_edge(row['CUI1'], row['CUI2'])\n",
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cd383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedre\\AppData\\Local\\Temp\\ipykernel_18108\\1232397527.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  MRCONSO2 = pd.read_csv(\"C:/Users/vedre/Downloads/2023AA/META//MRCONSO.RRF\",sep=\"|\",index_col=False,names=[\"CUI\",\"LAT\",\"TS\",\"LUI\",\"STT\",\"SUI\",\"ISPREF\",\"AUI\",\"SAUI\",\"SCUI\",\"SDUI\",\"SAB\",\"TTY\",\"CODE\",\"STR\",\"SRL\",\"SUPPRESS\",\"CVF\"])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f009dc6b1237409bab7f70fffeac1c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3144365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MRCONSO2 = pd.read_csv(\"C:/Users/vedre/Downloads/2023AA/META//MRCONSO.RRF\",sep=\"|\",index_col=False,names=[\"CUI\",\"LAT\",\"TS\",\"LUI\",\"STT\",\"SUI\",\"ISPREF\",\"AUI\",\"SAUI\",\"SCUI\",\"SDUI\",\"SAB\",\"TTY\",\"CODE\",\"STR\",\"SRL\",\"SUPPRESS\",\"CVF\"])\n",
    "\n",
    "MRCONSO2 = MRCONSO2[MRCONSO2[\"LAT\"] == 'ENG']\n",
    "MRCONSO2 = MRCONSO2[MRCONSO2[\"TS\"] == 'P']\n",
    "MRCONSO2\n",
    "\n",
    "MRCONSO2=MRCONSO2.drop_duplicates(subset=[\"CUI\"], keep=\"first\")\n",
    "MRCONSO2\n",
    "\n",
    "MRCONSO_dict = {}\n",
    "for _, row in tqdm(MRCONSO2.iterrows(), total=len(MRCONSO2)):\n",
    "    MRCONSO_dict[row[\"CUI\"]] = row[\"STR\"]\n",
    "\n",
    "def get_str(cui):\n",
    "    #return MRCONSO.loc[MRCONSO['CUI'] == cui][\"STR\"].iloc[0]\n",
    "    if cui in MRCONSO_dict:\n",
    "        return MRCONSO_dict[cui]\n",
    "    return \"NOT_FOUND\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the nodes to a list before sampling\n",
    "sampled_nodes = random.sample(list(G.nodes()), 8000)\n",
    "\n",
    "# Create a DataFrame with the required columns\n",
    "df = pd.DataFrame({\n",
    "    'Node': sampled_nodes,\n",
    "    'Node_Str': [get_str(node) for node in sampled_nodes]\n",
    "})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('regions_sampled_nodesjhjhkh.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b96247",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((get_str(\"C5169485\")).replace(\"&#x7C;\", \"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "62a9d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_yes = [\"C0228316\", \"C0443476\", \"C3495991\", \"C0225396\", \"C2328354\", \"C4246840\"]\n",
    "few_shot_no = [\"C0224412\", \"C0045044\", \"C0930750\", \"C1267424\", \"C1513124\", \"C1514049\"]\n",
    "few_shot_yes_1 = [\"C2328354\"]\n",
    "few_shot_no_1 = [\"C1514049\"]\n",
    "few_shot_no_3 = [\"C1514049\", \"C0926300\", \"C0830719\"]\n",
    "few_shot_yes_2 = [\"C2328354\", \"C0228316\"]\n",
    "few_shot_no_2 = [\"C1514049\", \"C0926300\"]\n",
    "few_shot_no_2_alt = [\"C0926300\", \"C1514049\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "865c34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def read_file_and_select_random(file_name, num_selections):\n",
    "    with open(file_name, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "    return random.sample(lines, min(num_selections, len(lines)))\n",
    "\n",
    "# Read and select from specified files\n",
    "\n",
    "yes_examples_codes = read_file_and_select_random('yes_regions_test.txt', 211)\n",
    "no_examples_codes = read_file_and_select_random('no_regions_test.txt', 789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de944e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Element to be replaced\n",
    "old_element = 'C2951504'\n",
    "\n",
    "# New element\n",
    "new_element = 'C5568032'\n",
    "\n",
    "# Find the index of the element to be replaced\n",
    "index = yes_examples_codes.index(old_element)\n",
    "\n",
    "# Replace the element\n",
    "yes_examples_codes[index] = new_element\n",
    "\n",
    "# Now your_list contains the new element instead of the old one\n",
    "print(yes_examples_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed16ac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(no_examples_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b482c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in yes_examples_codes:\n",
    "    print(get_str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a2e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 'yes_example_codes' to a file\n",
    "with open('yes_example_codes.txt', 'w') as file:\n",
    "    for item in yes_examples_codes:\n",
    "        file.write(f\"{item}\\n\")\n",
    "\n",
    "# Save 'no_example_codes' to a file\n",
    "with open('no_example_codes.txt', 'w') as file:\n",
    "    for item in no_examples_codes:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10c888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming MRCONSO_ENG DataFrame and yes_examples_codes list are defined\n",
    "\n",
    "# Filter the DataFrame for rows where the CUI is in your list\n",
    "filtered_df = MRCONSO_ENG[MRCONSO_ENG['CUI'].isin(yes_examples_codes)]\n",
    "\n",
    "# Normalize string case for case-insensitive duplicate removal\n",
    "filtered_df['STR_normalized'] = filtered_df['STR'].str.lower()\n",
    "\n",
    "# Drop duplicates based on CUI and normalized STR\n",
    "filtered_df = filtered_df.drop_duplicates(subset=['CUI', 'STR_normalized'])\n",
    "\n",
    "# Group by the 'CUI' column\n",
    "grouped = filtered_df.groupby('CUI')\n",
    "\n",
    "# Iterate over each group\n",
    "for cui, group in grouped:\n",
    "    # Extract the original string values (not the normalized ones)\n",
    "    string_values = group['STR'].tolist()\n",
    "    \n",
    "    # Print the CUI and its corresponding string values\n",
    "    print(f\"CUI: {cui}\")\n",
    "    print(\"String Variants:\")\n",
    "    for string in string_values:\n",
    "        print(string)\n",
    "    print(\"------\")  # Separator for clarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d094b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Continue using the previously filtered and grouped DataFrame\n",
    "grouped = filtered_df.groupby('CUI')\n",
    "\n",
    "# Initialize a list to hold the formatted strings\n",
    "formatted_strings = []\n",
    "\n",
    "# Iterate over each group\n",
    "for cui, group in grouped:\n",
    "    # Extract and clean the string values\n",
    "    string_values = [s.replace(\"&#x7C;\", \"|\") for s in group['STR'].tolist()]\n",
    "    \n",
    "    # Join string values with a specific separator (e.g., '; ')\n",
    "    joined_strings = '; '.join(string_values)\n",
    "    \n",
    "    # Format the string according to the specified structure\n",
    "    formatted_string = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\n Decide if the term, which has the following string example(s): {joined_strings} is referring to a part of the human nervous system. If multiple examples are given, treat them all as a whole and make your decision based on that. [/INST]\"\n",
    "    \n",
    "    # Add the formatted string to the list\n",
    "    formatted_strings.append(formatted_string)\n",
    "\n",
    "# Convert the list of formatted strings to a JSON array\n",
    "json_array = json.dumps(formatted_strings, indent=4)\n",
    "\n",
    "# Print or save the JSON array as needed\n",
    "print(json_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8da6db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Function to create few-shot examples without duplicates and considering capitalization\n",
    "def create_few_shot_examples(df, cui_list, answer):\n",
    "    few_shot_examples = []\n",
    "    for cui in cui_list:\n",
    "        # Filter DataFrame for current CUI and remove duplicates considering capitalization\n",
    "        strings_df = df[df['CUI'] == cui]\n",
    "        strings_df['STR_normalized'] = strings_df['STR'].str.lower()\n",
    "        strings_df = strings_df.drop_duplicates(subset=['STR_normalized'])\n",
    "\n",
    "        # Extract string values\n",
    "        string_values = strings_df['STR'].tolist()\n",
    "        joined_strings = '; '.join(string_values)\n",
    "\n",
    "        # Create the question with answer\n",
    "        question = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nExclude the only vascular structures, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that.Decide if the term, which has the following string example(s): {joined_strings} is related to the human nervous system. [/INST]\\n{answer}\"\n",
    "        few_shot_examples.append(question)\n",
    "    return few_shot_examples\n",
    "\n",
    "# Create few-shot examples\n",
    "few_shot_yes_examples = create_few_shot_examples(MRCONSO_ENG, few_shot_yes_2, 'yes')\n",
    "few_shot_no_examples = create_few_shot_examples(MRCONSO_ENG, few_shot_no_2_alt, 'no')\n",
    "\n",
    "# Combine few-shot examples\n",
    "all_few_shot_examples = few_shot_yes_examples + few_shot_no_examples\n",
    "\n",
    "# Main data processing\n",
    "filtered_df = MRCONSO_ENG[MRCONSO_ENG['CUI'].isin(yes_examples_codes)]\n",
    "filtered_df['STR_normalized'] = filtered_df['STR'].str.lower()\n",
    "filtered_df = filtered_df.drop_duplicates(subset=['CUI', 'STR_normalized'])\n",
    "\n",
    "grouped = filtered_df.groupby('CUI')\n",
    "formatted_strings_with_few_shot = []\n",
    "\n",
    "for cui, group in grouped:\n",
    "    string_values = [s.replace(\"&#x7C;\", \"|\") for s in group['STR'].tolist()]\n",
    "    joined_strings = '; '.join(string_values)\n",
    "    #formatted_string = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nDecide if the term, which has the following string example(s): {joined_strings} is directly related to the human nervous system. Exclude only vascular structures, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that. [/INST]\"\n",
    "    formatted_string = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nExclude the only vascular structures, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that.Decide if the term, which has the following string example(s): {joined_strings} is related to the human nervous system. [/INST]\"\n",
    "\n",
    "    # Prepend the few-shot examples to the formatted string\n",
    "    formatted_string_with_few_shot = '\\n'.join(all_few_shot_examples) + '\\n' + formatted_string\n",
    "    formatted_strings_with_few_shot.append(formatted_string_with_few_shot)\n",
    "\n",
    "# Convert to JSON array\n",
    "json_array_with_few_shot = json.dumps(formatted_strings_with_few_shot, indent=4)\n",
    "\n",
    "# Print or save the JSON array as needed\n",
    "print(json_array_with_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "aeeb2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Initialize a list to hold the formatted strings\n",
    "formatted_strings = []\n",
    "\n",
    "# Function to create few-shot examples without duplicates and considering capitalization\n",
    "def create_few_shot_examples(df, cui_list, answer):\n",
    "    few_shot_examples = []\n",
    "    for cui in cui_list:\n",
    "        # Explicitly create a copy of the DataFrame slice and remove duplicates considering capitalization\n",
    "        strings_df = df[df['CUI'] == cui].copy()\n",
    "        strings_df['STR_normalized'] = strings_df['STR'].str.lower()\n",
    "        strings_df = strings_df.drop_duplicates(subset=['STR_normalized'])\n",
    "\n",
    "        # Extract string values\n",
    "        string_values = strings_df['STR'].tolist()\n",
    "        joined_strings = '; '.join(string_values)\n",
    "\n",
    "        # Create the question with answer\n",
    "        question = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nDecide if the term: {joined_strings} is related to the human nervous system. Exclude the only vascular structures, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that. [/INST]\\n{answer}\"\n",
    "        #question = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nDecide if the term, which has the following example(s): {joined_strings} is related to neuroscience. Exclude the only vascular structures or genes, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that. [/INST]\\n{answer}\"\n",
    "        #question = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nExclude the only vascular structures, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that. Decide if the term, which has the following string example(s): {joined_strings} is related to the human nervous system. [/INST]\\n{answer}\"\n",
    "\n",
    "        few_shot_examples.append(question)\n",
    "    return few_shot_examples\n",
    "\n",
    "# Create few-shot examples\n",
    "few_shot_yes_examples = create_few_shot_examples(MRCONSO_ENG, few_shot_yes_1, 'yes')\n",
    "few_shot_no_examples = create_few_shot_examples(MRCONSO_ENG, few_shot_no_1, 'no')\n",
    "\n",
    "# Combine few-shot examples\n",
    "all_few_shot_examples = few_shot_yes_examples + few_shot_no_examples\n",
    "#all_few_shot_examples = few_shot_no_examples + few_shot_yes_examples\n",
    "\n",
    "# Main data processing\n",
    "filtered_df = MRCONSO_ENG[MRCONSO_ENG['CUI'].isin(no_examples_codes)].copy()\n",
    "filtered_df['STR_normalized'] = filtered_df['STR'].str.lower()\n",
    "filtered_df = filtered_df.drop_duplicates(subset=['CUI', 'STR_normalized'])\n",
    "\n",
    "grouped = filtered_df.groupby('CUI')\n",
    "formatted_strings_with_few_shot = []\n",
    "\n",
    "for cui, group in grouped:\n",
    "    string_values = [s.replace(\"&#x7C;\", \"|\") for s in group['STR'].tolist()]\n",
    "    joined_strings = '; '.join(string_values)\n",
    "    #formatted_string = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nDetermine if the following term, which has the following string example(s): {joined_strings} is related to the human nervous system. If multiple examples are given, treat them all as a whole and make your decision based on that.Consider 'yes' for neurotransmitters, cell receptors vital for nervous system functions, and hormones that significantly influence the nervous system. Respond 'no' for terms related more clearly to the vascular, lymphatic, skeletal, or muscular systems. If multiple examples are given, treat them all as a whole and make your decision based on that. [/INST]\"\n",
    "    formatted_string = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nDecide if the term: {joined_strings} is related to the human nervous system. Exclude the only vascular structures, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that. [/INST]\"\n",
    "    #formatted_string = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nDecide if the term, which has the following example(s): {joined_strings} is related to neuroscience. Exclude the only vascular structures or genes, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that. [/INST]\"\n",
    "    formatted_strings.append(formatted_string)\n",
    "\n",
    "    # Prepend the few-shot examples to the formatted string\n",
    "    formatted_string_with_few_shot = '\\n'.join(all_few_shot_examples) + '\\n' + formatted_string\n",
    "    formatted_strings_with_few_shot.append(formatted_string_with_few_shot)\n",
    "\n",
    "# Convert to JSON array\n",
    "json_array_with_few_shot = json.dumps(formatted_strings_with_few_shot, indent=4)\n",
    "\n",
    "# Write the JSON array to a file\n",
    "with open('reg_2_shot_no_17_test.json', 'w') as file:\n",
    "    file.write(json_array_with_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2ebed871",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming MRCONSO_ENG DataFrame and yes_examples_codes list are defined\n",
    "\n",
    "# Main data processing\n",
    "filtered_df = MRCONSO_ENG[MRCONSO_ENG['CUI'].isin(yes_examples_codes)].copy()\n",
    "filtered_df['STR_normalized'] = filtered_df['STR'].str.lower()\n",
    "filtered_df = filtered_df.drop_duplicates(subset=['CUI', 'STR_normalized'])\n",
    "\n",
    "grouped = filtered_df.groupby('CUI')\n",
    "formatted_strings = []\n",
    "\n",
    "for cui, group in grouped:\n",
    "    string_values = [s.replace(\"&#x7C;\", \"|\") for s in group['STR'].tolist()]\n",
    "    joined_strings = '; '.join(string_values)\n",
    "    formatted_string = f\"[INST] <<SYS>>\\nPlease answer with a 'yes' or a 'no' only!\\n<</SYS>>\\nDecide if the term, with the following example(s): {joined_strings} is related to the human nervous system. Exclude the only vascular structures, even if connected to the nervous system. If multiple examples or terms with multiple words are given, treat them all as a whole and make your decision based on that. [/INST]\"\n",
    "    formatted_strings.append(formatted_string)\n",
    "\n",
    "#{joined_strings}\n",
    "    \n",
    "# Convert to JSON array\n",
    "json_array = json.dumps(formatted_strings, indent=4)\n",
    "\n",
    "# Write the JSON array to a file\n",
    "with open('reg_0_shot_yes_29.json', 'w') as file:\n",
    "    file.write(json_array)\n",
    "\n",
    "print(\"JSON data saved to json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bbbf372c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined JSON file created at: reg_2_shot_1000_17_test.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Replace these with the paths to your files\n",
    "file_path1 = 'reg_2_shot_yes_17_test.json'\n",
    "file_path2 = 'reg_2_shot_no_17_test.json'\n",
    "output_file_path = 'reg_2_shot_1000_17_test.json'\n",
    "\n",
    "# Read the content of the first file\n",
    "with open(file_path1, 'r') as file:\n",
    "    data1 = json.load(file)\n",
    "\n",
    "# Read the content of the second file\n",
    "with open(file_path2, 'r') as file:\n",
    "    data2 = json.load(file)\n",
    "\n",
    "# Combine the data\n",
    "combined_data = data1 + data2\n",
    "\n",
    "# Write the combined data to a new file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(combined_data, file, indent=4)\n",
    "\n",
    "print(\"Combined JSON file created at:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
