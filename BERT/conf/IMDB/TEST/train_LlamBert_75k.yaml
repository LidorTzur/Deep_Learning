name: IMDB_TEST_LlamBert_75k
name_fields: !!python/tuple [model_name]
neptune_logging: True
train_fpath: /home/projects/DeepNeurOntology/IMDB_data/BERT_inputs/Llama_train_and_extra_75k.json
dev_fpath: null
test_fpath: /home/projects/DeepNeurOntology/IMDB_data/test.json
model_name: 
  # - distilbert-base-uncased
  # - bert-base-uncased
  # - bert-large-uncased
  - roberta-base
  - roberta-large
batch_size: 16
num_epochs: 5
max_len: 512
model_save_location: null
reduce_lines_for_testing: false # uses only 100 sentences to train model
lr: 0.000001
mislabel_percent: 0  # 0 if you don't want mislabeled data in the train set (not in val or test) 1 -> 1%, 2 -> 2% so on