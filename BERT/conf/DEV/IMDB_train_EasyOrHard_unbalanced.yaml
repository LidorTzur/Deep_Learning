name: IMDB_DEV_EasyOrHard_unbalanced
name_fields: !!python/tuple [model_name]
neptune_logging: True
train_fpath: /home/projects/DeepNeurOntology/IMDB_data/BERT_inputs/DEV/EasyOrHard_unbalanced/train.json
dev_fpath: /home/projects/DeepNeurOntology/IMDB_data/BERT_inputs/DEV/EasyOrHard_unbalanced/dev.json
test_fpath: /home/projects/DeepNeurOntology/IMDB_data/BERT_inputs/DEV/EasyOrHard_unbalanced/test.json
model_name: roberta-large
batch_size: 16
num_epochs: 20
max_len: 512
model_save_location: null
reduce_lines_for_testing: false # uses only 100 sentences to train model
lr: 0.0000001
mislabel_percent: 0  # 0 if you don't want mislabeled data in the train set (not in val or test) 1 -> 1%, 2 -> 2% so on
log_test_outputs: true